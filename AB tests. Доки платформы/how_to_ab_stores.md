## Как подготовить дизайн теста по магазинам

### Перед началом дизайна эксперимента

- Необходимо убедиться, что вы используете корректный дизайн А/Б теста и вам нужен дизайн именно тест по магазинам. Подумайте, нет ли у вас сетевого эффекта? Описание проблемы, когда тесты по магазинам не подойдут, есть в документации проведения [свитчбэк-теста](/how_to_switchback_ab.md). Если сомневаетесь, приходите с документацией теста в ~ab-stores.
- Определены магазины, которые могут участвовать в эксперименте (как в тестовой, так и контрольной группах)
- Определены метрики и минимальные ожидаемые эффекты для них
- У теста есть [документация](https://wiki.sbmt.io/pages/viewpage.action?pageId=3025185771) в [пространстве](https://wiki.sbmt.io/pages/viewpage.action?pageId=3022176076) платформы экспериментов

### Как использовать библиотеку

1. Клонировать этот репозиторий
`git clone https://gitlab.sbmt.io/analytics/datazone/ab_methodology.git`
2. Установить [poetry](https://python-poetry.org/docs/). Дополнительно про установку и использование poetry можно почитать [здесь](https://wiki.sbmt.io/display/ANLT/Poetry).
3. Проверить установку poetry: ``poetry --version`` 
4. Выполнить ``poetry install --no-root``
5. Если вы используете библиотеку из ноутбука: 
    - ``poetry add ipykernel``
    - ``poetry run python -m ipykernel install --user --name ab_methodology``
    - выбрать установленный кернел 
6. Заполнить .env файл с кредами к БД. Публичный файл лежит ``data/connectors.env``
7. Если запускаете библиотеку из ноутбука: ``%dotenv /full/path/to/connectors.env`` или ``load_dotenv("/full/path/to/connectors.env")``

#### Использование через .py файл

Передаем путь до конфига эксперимента и путь к .env файлу с кредами.

- Создание дизайна: `poetry run python get_test.py '/full/path/to/test_params_name.py' '/full/path/to/connectors.env'`
- Оценка эксперимента:  `poetry run python get_final_results.py '/full/path/to/test_params_name.py' '/full/path/to/connectors.env'`

#### Использование через ноутбук

Пример ноутбука лежит в [test_example.ipynb](notebooks/test_example.ipynb).  Это более гибкий инструмент, в котором можно воспользоваться функционалом, не поддерживаемом из коробки (дизайн для нескольких тестовых групп, использование MLM, загрузка результатов в сэндбокс). В тетрадке лежат и функции для дизайна, и для оценки.

#### Функционал библиотеки 

Помимо дизайна по магазинам функционал библиотеки позволяет рандомизировать по любой сущности, например, регион или ТД. Для этого в конфиге нужно проставить ``"other_column_id": True`` и указать как связаны имеющиеся в данных сущности с новой. Среди поддерживаемых по дефолту id есть `store_id_click`, `store_uuid`, `store_id_postgres`, `city_id`, `operational_zone_id`. Нужно добавить запрос в [other_id_functions](data/other_id_functions.py), в [merge_metrics_on](data/other_id_handle.py#L3) указать связку новой и страой сущности и добавить в [other_id_names](data/other_id_functions.py#L10) связку новой сущности и запроса для нее.


### Проверяем метрики

Многие метрики уже добавлены в соответствующий файл [metrics_functions.py](data/metrics_functions.py). Обязательными метриками для каждого эксперимента являются GMV, Gross Profit, AOV, количество заказов. Перед использованием стоит посмотреть, что запросы метрик соответствуют тому, что вы хотите посчитать. Например, убедитесь, что в запросе для метрики фильтрация по времени осуществляется по желаемой колонке (например, created_at или shipped_at). В случае, если метрика состоит из нескольких компонент, убедитесь, что все нужные компоненты указаны. Если вы не влияете на какие-то части “составной метрики”, их можно удалить для увеличения чувствительности. Например, по дефолту gmv считается как `gmv_advertising + gmv_service_fee_net_promo + gmv_goods_net_promo`, но вы в тесте влияете только на `gmv_goods_net_promo`, можно добавить новую метрику, состоящую только из `gmv_goods_net_promo`.

Обратите внимание, что в зависимости от того, в каком [блоке](https://wiki.sbmt.io/pages/viewpage.action?pageId=3025189720), то есть изолированной части заказа вы проводите изменение -- оформлении (то есть изменение связано с интерфейсом, с которым пользователь сталкивается до осуществления заказа) или execution (что происходит с заказом после того как пользователь оформил заказ, сборка, доставка, отмены) даты, по которым происходит фильтрация будут отличаться. Так для экспериментов в блоке оформления нужно использовать даты оформления заказа (completed_at), для блока execution -- даты доставки (shipped_at). Названия метик, которые считаются по shipped_at и эквивалентам должны заканчиваться на `_sh` (`gmv_sh`, `gross_profit_sh`). 

В общем случае не нужно ставить дополнительных фильтров на быструю/плановую доставку, наблюдения будут фильтроваться по генеральной совокупности. Однако для метрик, которые считаются по сменам (OPH, MPH, утилизация) нет однозначной привязки наблюдений к магазинам быстрой доставки. Запросы для быстрой и плановой разделены (`_express`, `_planned`), в тестах по магазинам **включение метрик, считающихся по сменам для тестов по быстрой доставке невозможно**. 

Найти существующую метрику можно по значению словаря [metrics_full_name](data/handle_metrics.py#L90) в [handle_metrics.py](data/handle_metrics.py) или по самим запросам в [metrics_functions.py](data/metrics_functions.py).

Для добавления метрик есть определенные требования, часть из них обусловлена функциональностью, часть удобством использования. Пожалуйста, придерживайтесь их.

1. Запросы для метрик хранятся в [metrics_functions.py](data/metrics_functions.py)
2. Для каждой метрики запросы для числителя и знаменателя пишутся отдельно. Для обозначения числителя мы добавляем к названию метрики `_num`, для знаменателя -- `_denom`.
3. Требования к функциям:
    1. Называется по имени метрики с префиксом get (например, get_gmv)
    2. В докстринге указаны пояснения к метрике / есть название тикета теста, в рамках которого метрика создается
    3. Принимает аргументы для фильтрации по времени `date_from` и `date_to`
4. В каждом запросе должны присутствовать следующие поля:
    1. Название метрики
    2. Дата в формате DateTime и названием Date
    3. Одно из обозначений магазина — `store_id_click` (id магазина в клике), `store_id_postgres` (id магазина в шоппере), `store_uuid` (uuid магазина)

Давайте добавим новую метрику — “Доля отмененных товаров по причине `Нет нужного товара`”. Она считается как $\frac{Кол-во\ отмененных\ товаров}{Все\ товары}$.  Метрики агрегируются суммой, поэтому для того, чтобы посчитать все товары для знаменателя, проставляем единицы. Обратим внимание, что числитель -- бинарная метрика, то есть для каждого заказа определяется, было ли опоздание. Добавим эти запросы в [metrics_functions.py](data/metrics_functions.py)

```python
def get_order_canc_no_good_num(start_date, end_date):
    """Доля отмен по причине Нет нужного товара для AB-1012 (числитель)"""

    q = f"""
    select toDate(period_dt) as Date,
           store_id as store_id_click,
           case when shipment_state='canceled' and goods_instamart=0 and bb_sert=0 and cancellation_reason_nm = 'Нет нужного товара' then 1 else 0 end as orders_canc_no_good_num
    from dm.bi__shipments_financial
    where toDate(period_dt) >= ('{start_date}')
    and toDate(period_dt) <= ('{end_date}')
    """
    return read_sql_query(q, con="click")

def get_order_canc_no_good_denom(start_date, end_date):
    """Доля отмен по причине Нет нужного товара для AB-1012 (знаменатель)"""

    q = f"""
    select toDate(period_dt) as Date,
           store_id as store_id_click,
					 1 as orders_canc_no_good_denom
    from dm.bi__shipments_financial
    where toDate(period_dt) >= ('{start_date}')
    and toDate(period_dt) <= ('{end_date}')
    """
    return read_sql_query(q, con="click")
```

Дальше обновим [handle_metrics.py](data/handle_metrics.py).  Добавим название метрики ``order_canc_no_good`` и числитель и знаменатель. Если знаменателя нет, на его месте нужно написать None. Важно, чтобы название метрики в данных совпадало с названием ключа в словаря. 

```python
metrics_definition = {...,
											"order_canc_no_good": ["order_canc_no_good_num", "order_canc_no_good_denom"]
}
```

Для числителя и знаменателя (если он есть), нужно заполнить словарь с указанием на соответствующие им функции.

```python
metrics_func = {...,
							  "order_canc_no_good_num": get_order_canc_no_good_num,
							  "order_canc_no_good_denom": get_order_canc_no_good_denom
}
```

Добавляем полные названия для всей метрики:

```python
metrics_full_name = {...,
										"order_canc_no_good": "Доля отмен по причине 'Нет нужного товара'"
}
```

После того как вы добавите новые метрики, не забудьте сделать MR. Чтобы убедиться, что запросы и функции для метрик корректные, стоит воспользоваться [ноутбуком](notebooks/check_metrics.ipynb) или напрямую функцией [check_metrics](test_collection/check_metrics.py). Для тестов по магазинам нужно задать ``stores_test=True``. 


### Создаем файл генеральной совокупности

В этом файле передаются все магазины, которые могут быть в эксперименте (как в тестовой, так и контрольной группах). Часто мы можем включить только магазины быстрой или плановой доставок, не хотим включать магазины из технического теста. Таких условий может быть очень много, поэтому мы ожидаем, что вы  передадите список из точек, которые уже подпадают по условие. Перед выбором магазинов для участия в эксперименте, убедитесь, что они доступные и в них были заказы за последний месяц.

Поддерживаются .csv файлы, с разделителем запятой. Проверьте, что в вашем файле нет пропусков.

- в файле должен присутствовать uuid магазина (`store_uuid`) / id магазина из клика (`store_id_click`) / id магазина из шоппера (`store_id_postgres`)
- в файле должно быть значение из `filter_column_id` конфига

Пример колонок: store_uuid, operational_zone_id, city_id

### Заполнение конфига

Конфиг представлен в виде словаря, на его заполненную версию можно посмотреть [здесь](test_params/test_params_ab_xxx.py).

`test_name` — номер задачи

Мы рекомендуем оставлять именно номер задачи, а не название, тк по нему проще всего определить, какая фича тестируется и кто этот тест проводит. В задачке также стоит указать ссылку на документацию с описанием и результатами.

`gen_pop_csv_file_path` -- путь до .csv файла с юнитами генеральной совокупности (например, все магазины, которые могут участвовать в эксперименте)

`w_length` -- длина теста в неделях

Длина эксперимента должна быть кратна 7, это связано с сезонностью и возможно разными эффектами в будни и в выходные, поэтому минимальная рекомендуемая длина теста — 2 недели. С увеличением длины теста до 4х недель мощность увеличивается не сильно, при возможности стоит увеличивать именно кол-во магазинов.

`filter_column_id` -- название колонки для фильтрации всех метрик по юнитам генеральной совокупности

Обсудили это в части про файл генеральной совокупности, напомню, что название в параметре `filter_column_id` должно быть в файле. Метрики фильтруются по id магазина, поэтому поддерживаются следующие поля: uuid магазина (`store_uuid`) / id магазина из клика (`store_id_click`) / id магазина из шоппера (`store_id_postgres`)

`effects` -- словарь метрика-эффект,

Указывается полное название метрики ,оно должно соответствовать названию метрики из [metrics_definition](data/handle_metrics.py#L5)

`stratification_params` -- параметры стратификации

- `group_shares` -- список с долями каждой группы, при запуске из файла поддерживаются только 2 группы
- `traffic_size` -- доля трафика (юнитов генеральной совокупности), которую можно сплитовать

    Иногда мы хотим взять только часть генеральной совокупности в тест, например, если раскатка фичи очень дорогая. Однако стоит помнить, что при сокращении генеральной совокупности, мощность будет сокращаться.

- `n_splits` -- количество сплитов для симуляций

    Использование большего кол-ва сплитов помогает повысить точность оценки FPR и мощности, к тому же после фильтрации должно оставаться достаточное кол-во сплитов. Минимальное рекомендуемое кол-во здесь 1000.

- `id_column` -- название колонки-юнита рандомизации

    В тесте по магазинам здесь ожидается id магазина. Напомню, что значение `id_column` должно быть колонкой в файле генеральной совокупности.

- `num_metrics` -- список с количественными метриками

    Сейчас в качестве метрик стратификации поддерживаются только метрики, добавленные в конфиг в качестве метрик эксперимента. Хорошей практикой является использование финансовых и целевых метрик.

- `cat_metrics` -- список с категориальными метриками

    Поддерживается добавление retailer_id / city_id.

- `n_bins` — кол-во бинов для разбиения количественных метрик

    Чем больше это значение, тем больше будет страт. Мы не хотим, чтобы страт было слишком много, тогда это будет не лучше случайного разбиения. В логах эксперимента можно найти кол-во получившихся страт.

- `filter_metric` -- метрика для фильтрации по медиане дневного расхождения групп

    После того как мы получили стратифицированные сплиты, мы дополнительно фильтруем их по медиане дневного расхождения групп. Так мы выбираем более подходящие сплиты, где между группами нет большого расхождения. Сейчас мы поддерживаем фильтрацию только по одной метрикой, хорошей практикой будет использование здесь целевой метрики.

- `threshold` -- трэшхолд для фильтрации, %

    Часто мы выбираем значение 1-5%. Мы не хотим, чтобы осталось несколько сплитов, тогда мы не сможем корректно оценить FPR. В логах эксперимента можно найти кол-во оставшихся сплитов.


`mlm_params` -- словарь с параметрами для MLM

Иногда бывает, что нас не устраивает FPR/мощность, полученная через CUPED. Тогда мы можем использовать методы, которые мы применяем в свитчбэк-экспериментах (MLM и CRSE). Они могут давать гораздо меньший FPR и более высокую мощность. Однако их немного сложнее применить и интерпретировать в разрезе тестов по магазинам. В этих методах нужно использовать данные на уровне заказа, поэтому данные, получаемые для обычного теста не подходят.

Функционал не поддерживается при использовании из файла напрямую, но им можно пользоваться в ноутбуке. Если у вас возникли сложности, напишите в ~ab-stores.

- `unit_interest` -- название группы-кластера для моделирования случайного наклона (например, city_id)

### Загрузка конфига 

После разработки дизайна конфиг нужно загрузить в соответствующую таблицу sandbox.ab_stores_test_params при помощи [upload_test_params](test_collection/utils_upload_splits.py#L111). 

### Результат использования

Результаты выполнения, описанные далее, пишутся в директорию с названием теста.

**Общая информация**:

- `test_name.log` -- файл с логами дизайна, здесь можно узнать, на какой стадии находится дизайн, какие файлы и куда сохраняются, какие ошибки возникают в процессе

**Данные**
По дефолту не сохраняются, однако при ручном дизайне вы можете передать параметр save=True в [get_all_data](data/get_data.py#L145) и [get_splits](data/get_splits.py#L19) для сохранения следующих файлов:

- `filtered_obs_AB_test_name_date_dump.pkl` -- данные до агрегации за observational период
- `filtered_exp_AB_test_name_date_dump.pkl` -- данные до агрегации за experimentational период
- `obs_agg_AB_test_name_dump.pkl` -- агрегированные данные obervational периода
- `exp_agg_AB_test_name_dump.pkl` -- агрегированные данные obervational периода
- `test_name_split.pkl` -- все стратифицированные сплиты, которые использовались для симуляций

**Дизайн**

- `FPR_test_name.md` -- таблица с FPR на АА для каждой метрики на 1% и 5% уровне значимости
- `power_test_name.md` -- таблица с мощностью на AB для каждой метрики на 1% и 5% уровне значимости
- `effect_distribution_test_name.md` -- таблица с синтетическим эффектом (mean и std) для метрик
- `test_name_metric_method_AA_plot.png` -- CDF plot для отдельной метрики на АА тесте
- `test_name_metric_method_AB_plot.png` -- CDF plot для отдельной метрики на АB тесте

### Что делать, если FPR больше уровня значимости? 
- Перейти к 1% уровню значимости. Напомним, что и мощность мы будем считать на уровне 1% 
- Если вы оценивали с помощью CUPED, оценить с помощью CRSE или MLM. [Ноутбук](notebooks/ab_stores_with_MLM.ipynb) для оценки.  
- Удалить выбросы 
- Декомпозировать метрику. Например, gmv считается как gmv_advertising + gmv_service_fee_net_promo + gmv_goods_net_promo, возможно ваша фича действует только на одну из этих компонент, можно оставить только ее

### Что делать, если мощность недостаточна? 
- Увеличить кол-во доступных юнитов (увеличить кол-во доступных магазинов, ритейлеров или городов) 
- Увеличить длительность эксперимента 
- Если вы оценивали с помощью CUPED, оценить с помощью CRSE или MLM. [Ноутбук](notebooks/ab_stores_with_MLM.ipynb) для оценки.  
- Удалить выбросы 
- Декомпозировать метрику. Например, gmv считается как gmv_advertising + gmv_service_fee_net_promo + gmv_goods_net_promo, возможно ваша фича действует только на одну из этих компонент, можно оставить только ее

### Обновление сплита 
Дата начала в финальном сплите проставляется, начиная с завтрашнего дня от момента его подготовки. Мы рекомендуем обновлять сплит при переносе сроков сплита (например, если техническая реализация проведения тестов появляется позже). Группы со временем становятся менее похожими друг на друга, и полученные FPR и мощность уже не являются валидными. 

### Добавление информации о тесте в sandbox

После того как вы убедились, что дизайн вашего теста проходит по FPR/мощности и получили сплит, его стоит загрузить в `sandbox.splits_ab_stores`. Сейчас это поддерживается только при ручном дизайне.  Для этого воспользуйтесь функцией [upload_final_split](test_collection/utils_upload_splits.py).  Это важно при планировании тестов, чтобы развести с потенциально пересекающимися тестами. Также вы можете использовать данные из таблицы при построении дашборда.

### Подведение результатов

Для получения оценки эксперимента заполняются следующие поля:

- `fact_start_date`- дата начала эксперимента в формате YYYY-MM-DD
- `fact_end_date` -- дата окончания эксперимента в формате YYYY-MM-DD

Сплит эксперимента должен называться по формату “split_test_name.csv”, где test_name — поле конфига. Проверьте, что файл так называется.  Для оценки нужно запустить функцию [get_cuped_results](test_collection/get_estimations.py#L20)

Абсолютные значения метрик оцениваются на уровне магазина/дня.

Что делать, если вы уже провели тест и вам нужно посчитать новую метрику? Включить ее в расчеты просто так нельзя. Сначала с ней нужно провести АА тесты, убедиться, что доля ложных прокрасов при выбранном уровне значимости подходит, и только потом оценивать ее в эксперименте. Если тест был давно, АА тесты нужно считать на датах эксперимента. К сожалению, автоматически сейчас это сделать нельзя.

### Что-то случилось

Если что-то не получается или осталось непонятным, у вас есть запрос на добавление функционала или вы заметили ошибку, пишите в ~ab-stores.
